# SignSpeak: AI-Powered Sign Language Interpretation
Team Members:

Najeeb Fariduddin Saiyed

Godcares Ndubuisi


## Introduction

SignSpeak is an innovative project leveraging the power of Artificial Intelligence (AI) to bridge the communication gap for the deaf and hard-of-hearing community by accurately translating various sign languages into spoken languages. This project acknowledges the diversity in sign languages across different countries and aims to create tailored AI models for each.

## Motivation

Our motivation is rooted in inclusivity and accessibility. With millions of individuals relying on sign language globally, there's an urgent need for technology that can translate sign language efficiently and accurately. SignSpeak is committed to enhancing communication, promoting understanding, and ensuring that deaf and hard-of-hearing individuals have equal access to information and opportunities.

## Features

- **Multi-Country Sign Language Support:** Custom models for different countries' sign languages.
- **Real-Time Translation:** Fast, efficient, and accurate translation of sign language (images) into `text` and `speech` 
- **User-Friendly Interface:** An intuitive and accessible application interface.
- **Continuous Learning & Improvement:** Regular updates to models based on user feedback and new research.

## Flow Chart

![image](https://github.com/iamzayd/GDSC-Solution-Challenge-Sign-Speak/assets/91972048/ac41e05c-f7bd-4c32-a773-dc25eb819215)

## Structure

The project is organized into three main folders, each focusing on a different level of sign language recognition:

1. **Alphabet Level**: 
   - This folder contains resources and scripts focused on recognizing individual sign language letters. It includes datasets of sign language alphabets and scripts that can identify and interpret these signs.

2. **Word Level**: 
   - In this folder, you'll find materials related to the recognition of signed words. It encompasses a more complex dataset that combines individual signs into words, along with scripts and models that focus on word-level recognition.

3. **Sentence Level**: 
   - This folder is dedicated to understanding and interpreting full sentences in sign language. It includes advanced models and datasets designed to comprehend the syntax and structure of sign language sentences, offering a comprehensive understanding of signed communication.

## Installation

1. **Clone the repository:**
   `git clone [repository URL]`

2. Change File paths in notebooks you decide to run.

3. Run the desired Python notebooks.

